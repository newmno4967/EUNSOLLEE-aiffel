{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haedongmu/AIFFEL_quest_cr/blob/main/Python/Py02/py02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def pre_process_word(content):\n",
        "  content = content.lower() # 모든 문자를 소문자로 변환\n",
        "  content = content.replace(\"'\",\" \") # ' 를 공백으로 대체\n",
        "  content = re.sub(r'[^a-z\\s]', '', content) # a-z를 제외한 나머지 문자(기호)를 제거\n",
        "\n",
        "  return content\n",
        "\n",
        "# 텍스트를 입력받고 빈도수 계산하는 함수\n",
        "def get_word_frequency_dict():\n",
        "  file_path = '/content/sample_data/Avengers.txt'\n",
        "\n",
        "  # 텍스트 처리\n",
        "  with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    content =  pre_process_word(f.read())\n",
        "\n",
        "  # 단어 빈도수 계산\n",
        "  words = content.split() # 공백 기준으로 단어 분리\n",
        "  word_frequencies = Counter(words) # 단어 빈도수 계산\n",
        "\n",
        "  # 값이 큰 순서대로 내림차순 정렬\n",
        "  sorted_word_frequencies = dict(sorted(word_frequencies.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "  # 순차적인 인덱스를 값으로 할당\n",
        "  renumbered_frequencies = {word: idx for idx, (word, freq) in enumerate(sorted_word_frequencies.items())}\n",
        "\n",
        "  return renumbered_frequencies\n",
        "\n",
        "# 단어의 빈도수를 저장한 딕셔너리 읽기\n",
        "word_frequency_dict = get_word_frequency_dict()\n",
        "\n",
        "# 사용자로부터 텍스트 입력 받기\n",
        "user_input = input(\"문장을 입력해 주세요.\")\n",
        "user_input = pre_process_word(user_input)\n",
        "user_input_words = user_input.split() # 공백 기준으로 단어 분리\n",
        "\n",
        "# 이터레이터 생성\n",
        "words_iterator = iter(user_input_words)\n",
        "words_list = []\n",
        "\n",
        "# 이터레이터에서 단어를 하나씩 꺼내기\n",
        "try:\n",
        "    while True:\n",
        "        word = next(words_iterator)  # 이터레이터에서 단어 하나씩 꺼내기\n",
        "        if word in word_frequency_dict:\n",
        "          word_frequency = word_frequency_dict[word]\n",
        "        else:\n",
        "          word_frequency = -1\n",
        "\n",
        "        words_list.append(word_frequency)\n",
        "\n",
        "except StopIteration:\n",
        "    # 이터레이터가 끝에 도달하면 StopIteration 예외 발생\n",
        "    print(\"모든 단어를 처리했습니다.\")\n",
        "\n",
        "print('**'*10)\n",
        "print(words_list)\n",
        "print('**'*10)\n",
        "\n",
        "\n",
        "'''\n",
        "# 권중 네비게이터\n",
        "초반에 구글드라이브 설정에 시간을 많이 빼았겼습니다.\n",
        "또한 코드 작성을 따로 하다가 지난 번에 했던 것이 생각나서 뒤늦게 같이 하게 되었습니다.\n",
        "그래서 어쩔 수 없이 시간이 부족하여 구글의 도움을 받을 수 밭게 없었고,\n",
        "수업시간에 배우지 않은 부분을 많이 넣게 되었습니다.\n",
        "전체적인 프로세스는 다음과 같이 진행하였습니다.\n",
        "1. 단어 전처리 함수작성\n",
        "   1) 소문자 변환\n",
        "   2) '는 공백으로 변환\n",
        "   3) 알파벳 제외한 문자는 삭제\n",
        "2. 텍스트 파일을 읽어서 단어별로 출현빈도를 기록한 딕셔너리 만들기\n",
        "3. 사용자로부터 문장을 입력받은 후 단어 전처리 함수를 통해 전처리 한 후 이터레이터를 사용하여 단어단위로 딕셔너리에 대입하여 인덱스을 읽어서 리스트에 저장\n",
        "4. 리스트를 출력\n",
        "\n",
        "# 최유진 드라이버\n",
        "처음에 각자 진행하는 줄 알아서 시간이 더 소요됐습니다\n",
        "그리고 배운 내용보다 검색의 도움을 더 받은 것 같습니다 ㅠㅠ 너무 어려웠어요 팀원이신 권중 네비게이터님이 많이 도와주셨습니다\n",
        "조건을 차례대로 수행하는데 오류가 생겨서 계속 수정했습니다\n",
        "그리고 저번 시간에 막 배운 데코레이션도 추가해봤습니다!\n",
        "완성했지만 살짝 아쉬움도 느껴지는 테스트였습니다 좀 더 분발하겠슴니다...\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "G_vDKzJtl7-D",
        "outputId": "15172ab5-7aa1-474f-cc30-dca54b7eef59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "문장을 입력해 주세요.I am a boy\n",
            "모든 단어를 처리했습니다.\n",
            "********************\n",
            "[2, 120, 3, 535]\n",
            "********************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n초반에 구글드라이브 설정에 시간을 많이 빼았겼습니다.\\n또한 코드 작성을 따로 하다가 지난 번에 했던 것이 생각나서 뒤늦게 같이 하게 되었습니다. \\n그래서 어쩔 수 없이 시간이 부족하여 구글의 도움을 받을 수 밭게 없었고,\\n수업시간에 배우지 않은 부분을 많이 넣게 되었습니다.\\n전체적인 프로세스는 다음과 같이 진행하였습니다.\\n1. 단어 전처리 함수작성 \\n   1) 소문자 변환\\n   2) '는 공백으로 변환\\n   3) 알파벳 제외한 문자는 삭제\\n2. 텍스트 파일을 읽어서 단어별로 출현빈도를 기록한 딕셔너리 만들기\\n3. 사용자로부터 문장을 입력받은 후 단어 전처리 함수를 통해 전처리 한 후 이터레이터를 사용하여 단어단위로 딕셔너리에 대입하여 인덱스을 읽어서 리스트에 저장\\n4. 리스트를 출력\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}